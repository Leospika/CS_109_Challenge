{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CS 109 Extension Project",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T00:31:57.274901Z",
     "start_time": "2025-11-20T00:31:57.265990Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Hello World!\")",
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T06:57:09.273671Z",
     "start_time": "2025-12-01T06:45:58.936113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Goal: Get Live Feed Data\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "\n",
    "# make a directory for the data\n",
    "download_directory = \"data\"\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(download_directory, exist_ok=True)\n",
    "\n",
    "# mark how many days in each month\n",
    "days = {2: 28, 4: 30, 6: 30, 9: 30, 11: 30}\n",
    "\n",
    "for i in range(1, 13):\n",
    "    day = 0\n",
    "    if i in days:\n",
    "        day = days[i]\n",
    "    else:\n",
    "        day = 31\n",
    "\n",
    "    for j in range(1, day + 1):\n",
    "        file_name = f\"subwaydatanyc_2023-{i:02}-{j:02}_csv.tar.xz\"\n",
    "        full_path = os.path.join(download_directory, file_name)\n",
    "\n",
    "        url = f\"https://subwaydata.nyc/data/{file_name}\"\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                with open(full_path, \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "            else:\n",
    "                print(f\"Error {response.status_code} accessing: {file_name}\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Connection Error for {file_name}: {e}\")\n",
    "            time.sleep(5) # Wait longer after a connection error"
   ],
   "id": "606e0b4a0526182e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leomelton/PyCharmMiscProject/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T08:02:01.900978Z",
     "start_time": "2025-12-01T08:02:01.774367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract from .tar.xz file extension\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "# 1. Define the necessary file paths\n",
    "data_directory = \"data\"\n",
    "archive_file = os.path.join(data_directory, 'subwaydatanyc_2023-01-01_csv.tar.xz')\n",
    "extract_dir = 'extracted_csv_data'\n",
    "target_file_in_archive = 'subwaydatanyc_2023-01-01_stop_times.csv'\n",
    "\n",
    "# 2. Create the extraction directory\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "print(f\"Extraction directory is set to: {extract_dir}\")\n",
    "\n",
    "# 3. Open the archive and extract only the target file\n",
    "try:\n",
    "    print(f\"Starting extraction of ONLY {target_file_in_archive} from {archive_file}...\")\n",
    "\n",
    "    # 'r:xz' opens the file for reading and handles the XZ decompression\n",
    "    with tarfile.open(archive_file, 'r:xz') as tar:\n",
    "\n",
    "        # Check if the desired file exists in the archive (good practice)\n",
    "        if target_file_in_archive in tar.getnames():\n",
    "            # Extract ONLY the specified file to the target directory\n",
    "            tar.extract(target_file_in_archive, path=extract_dir)\n",
    "\n",
    "            # 4. Construct the full path to the extracted file\n",
    "            extracted_path = os.path.join(extract_dir, target_file_in_archive)\n",
    "\n",
    "            print(f\"\\n✅ Success: '{target_file_in_archive}' extracted to: {extracted_path}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\n❌ Error: '{target_file_in_archive}' was not found inside the archive.\")\n",
    "\n",
    "except tarfile.ReadError:\n",
    "    print(f\"\\n❌ Error: Could not read or decompress the archive '{archive_file}'. Check file integrity.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ An unexpected error occurred: {e}\")"
   ],
   "id": "6945a3aa68321f67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction directory is set to: extracted_csv_data\n",
      "Starting extraction of ONLY subwaydatanyc_2023-01-01_stop_times.csv from data/subwaydatanyc_2023-01-01_csv.tar.xz...\n",
      "\n",
      "✅ Success: 'subwaydatanyc_2023-01-01_stop_times.csv' extracted to: extracted_csv_data/subwaydatanyc_2023-01-01_stop_times.csv\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T08:32:56.300968Z",
     "start_time": "2025-12-01T08:32:56.191547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Analyze File to Get Trend\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"extracted_csv_data/subwaydatanyc_2023-01-01_stop_times.csv\")\n",
    "\n",
    "df['next_actual_departure'] = df.groupby('trip_uid')['marked_past'].shift(-1)\n",
    "\n",
    "df['actual_duration_seconds'] = (\n",
    "    df['next_actual_departure'] - df['marked_past']\n",
    ")\n",
    "\n",
    "df['next_scheduled_departure'] = df['departure_time'].shift(-1)\n",
    "\n",
    "df['expected_duration_seconds'] = (\n",
    "    df['next_scheduled_departure'] - df['departure_time']\n",
    ")\n",
    "\n",
    "df_filtered = df[df['actual_duration_seconds'] > (df['expected_duration_seconds'] * 0.5)]\n",
    "df_filtered = df_filtered[df_filtered['actual_duration_seconds'] > 30]\n",
    "\n",
    "df_filtered['delay_added_seconds'] = (\n",
    "    df_filtered['actual_duration_seconds'] - df_filtered['expected_duration_seconds']\n",
    ")\n",
    "\n",
    "# 8. Clean Up (Remove last stop of every trip)\n",
    "df_final = df_filtered.dropna(subset=['delay_added_seconds'])\n",
    "\n",
    "print(df_final.iloc[:, 10:])\n",
    "print(df_final.shape[0])"
   ],
   "id": "8b84783e5d46f399",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        expected_duration_seconds  delay_added_seconds\n",
      "0                           150.0                  0.0\n",
      "1                           109.0                -19.0\n",
      "2                            79.0                 11.0\n",
      "3                            76.0                 -1.0\n",
      "4                            81.0                  0.0\n",
      "...                           ...                  ...\n",
      "155523                      213.0                 -3.0\n",
      "155524                      184.0                -73.0\n",
      "155548                      160.0                -73.0\n",
      "155572                      120.0                  0.0\n",
      "155573                       66.0                 -4.0\n",
      "\n",
      "[130929 rows x 2 columns]\n",
      "130929\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T08:27:49.632597Z",
     "start_time": "2025-12-01T08:27:49.578252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's analyze this data!\n",
    "\n",
    "F_delay = 0\n",
    "F_count = 0\n",
    "total_average = df_final['delay_added_seconds'].mean()\n",
    "\n",
    "df_subway_only = df_final[~df_final['stop_id'].str.startswith('S')].copy()\n",
    "df_f_train = df_subway_only[\n",
    "    df_subway_only['trip_uid'].astype(str).str.contains('F')\n",
    "].copy()\n",
    "F_average = df_f_train['delay_added_seconds'].mean()\n",
    "\n",
    "print(F_average)\n",
    "print(total_average)"
   ],
   "id": "ab48745ec75404b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.006378189094547274\n",
      "2.0375928938585033\n"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
